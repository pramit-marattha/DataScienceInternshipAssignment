{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HandWritten Digit Recognition using MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D, Dropout, Convolution2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data(path='mnist.npz'):\n",
    "#     path = get_file(path, origin='https://s3.amazonaws.com/img-datasets/mnist.npz', file_hash='8a61469f7ea1b51cbae51d4f78837e45')\n",
    "#     with np.load(path, allow_pickle=True) as f:\n",
    "#         X_train, y_train = f['x_train'], f['y_train']\n",
    "#         X_test, y_test = f['x_test'], f['y_test']\n",
    "#     return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "##### Reshaping the dataset inputs \"\"\" X_train & X_test \"\"\" to the shape that our model expects when training the model. \n",
    "###### Number of train sets \"\"\"X_train =====> 60000\"\"\"\",\n",
    "###### Number of test sets\"\"\"\" X_test =====> 10000\"\"\". \n",
    "###### shape of each image that is 28 * 28 pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking out the shapes involved in dataset\n",
    "# print (\"X_train:=====> {}\".format(X_train.shape))\n",
    "# print (\"y_train:=====> {}\".format(y_train.shape))\n",
    "# print (\"X_test: =====> {}\".format(X_test.shape))\n",
    "# print (\"y_test: =====> {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping so as to convert images for our model\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:=====> (60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print (\"X_train:=====> {}\".format(X_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train:=====> (60000,)\n"
     ]
    }
   ],
   "source": [
    "print (\"y_train:=====> {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: =====> (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print (\"X_test: =====> {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test: =====> (10000,)\n"
     ]
    }
   ],
   "source": [
    "print (\"y_test: =====> {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding (Encoding the target variable.)\n",
    "###### coloumn will be created for each output and a binary variable is inputted for each kind\n",
    "Example ===> If image is of number 2 then it will be something like this ==> [0,0,1,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the labels \n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building  model\n",
    "\n",
    "Sequential model is used because it is the easiest way to build a model in Keras.<br>\n",
    "It allows to build the model layer by layer.<br>\n",
    "*add()* is used for adding various layers.<br><br>                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and declaring the layer\n",
    "\n",
    "\n",
    "##### Kernel_Size\n",
    "It is the size of the filter matrix for the convolution.<br>\n",
    "kernel_size = 3 means that a 3x3 filter matrix is going to be used.<br>\n",
    "##### pool_size\n",
    "It is refered to the size of the filter window which will be used by MaxPooling Layers for the max pooling operation.<br> \n",
    "pool_size = 2 means that a 2x2 window will be used for performing each iteration of max pooling operation.<br>\n",
    "##### Activation \n",
    "It is the activation function for the layer.<br> \n",
    "activation = 'ReLU' (Rectified Linear Activation). \n",
    "This activation function is known for performing well in terms of speed and output in the neural network.\n",
    "(In simple languge it speeds up the performance.)\n",
    "<br>\n",
    "Takes shape of 28 by 28 and 1 where 1 signifies as the greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "FirstLayer = Convolution2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max pooling layer 1 will fed to the next convolutional layer of 2 out of 32 layer nodes which will perform convolution operation on it using a window of size 3*3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "SecondLayer = MaxPooling2D(pool_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then this max pooling layer 2 will do the asme max pooling operation as the above layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "ThirdLayer = Convolution2D(32, kernel_size=3, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "FourthLayer = MaxPooling2D(pool_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below dropout layer simplify the network further performing the dropout regularization.\n",
    "It drops out the random nodes from the network\n",
    "The number of nodes to be dropped depends on the comparison between each nodes achieved and the probabiltiy we provide "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "FifthLayer = Dropout(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Half of the nodes will be dropped because the we are setting up th eprobability to 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "SixthLayer = Flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flatten \n",
    "The connection between convolution and the dense layers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "SeventLayer = Dense(128, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using dense layer with relu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "EighthLayer = Dropout(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "NinthLayer = Dense(10, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final dense layer with the activation softmax it acts as the output layer for the network \n",
    "\n",
    "It consists of 10 nodes in our output layer one for each possible outcome which is from 0 to 9 \n",
    "\n",
    "softmax makes the output sum up to 1 , so that the output contains a series of possibillities \n",
    "finally the moderl can now predict the one with highest probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the layers to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(FirstLayer)\n",
    "model.add(SecondLayer)\n",
    "model.add(ThirdLayer)\n",
    "model.add(FourthLayer)\n",
    "model.add(FifthLayer)\n",
    "model.add(SixthLayer)\n",
    "model.add(SeventLayer)\n",
    "model.add(EighthLayer)\n",
    "model.add(NinthLayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow of the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile model\n",
    "Three parameter names __optimizer__ ,__loss function__ and __metrics__ is used. \n",
    "- __Optimizer__ - It controls the learning rate. We will be using 'adam' optimizer. It is a very good optimizer as it utilises the perks of both Stochastic gradient and RMSprop optimizers.\n",
    "- __Loss function__ - We will be using 'categorical_crossentropy' loss function. It is the most common choice for classification. A lower score corresponds to better performance.\n",
    "- __Metrics__ - To make things easier to interpret, we will be using 'accuracy' metrix to see the accuracy score on the validation set while training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'optimizer' controls the learning rate \n",
    "\n",
    "Using 'categorical_crossentropy' loss function because it is commonly used for classification \n",
    "\n",
    "using the accuracy matrix to see the accuracy score on the validation set while training the model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 46s 24ms/step - loss: 0.9262 - accuracy: 0.7617 - val_loss: 0.1196 - val_accuracy: 0.9642\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 45s 24ms/step - loss: 0.2727 - accuracy: 0.9199 - val_loss: 0.0700 - val_accuracy: 0.9780\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 52s 28ms/step - loss: 0.2061 - accuracy: 0.9388 - val_loss: 0.0595 - val_accuracy: 0.9809\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 50s 27ms/step - loss: 0.1736 - accuracy: 0.9489 - val_loss: 0.0527 - val_accuracy: 0.9825\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 51s 27ms/step - loss: 0.1592 - accuracy: 0.9527 - val_loss: 0.0504 - val_accuracy: 0.9832\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 46s 25ms/step - loss: 0.1444 - accuracy: 0.9581 - val_loss: 0.0525 - val_accuracy: 0.9840\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 52s 28ms/step - loss: 0.1361 - accuracy: 0.9611 - val_loss: 0.0539 - val_accuracy: 0.9833\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 57s 30ms/step - loss: 0.1273 - accuracy: 0.9638 - val_loss: 0.0384 - val_accuracy: 0.9871\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 49s 26ms/step - loss: 0.1228 - accuracy: 0.9652 - val_loss: 0.0409 - val_accuracy: 0.9882\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 52s 28ms/step - loss: 0.1175 - accuracy: 0.9661 - val_loss: 0.0408 - val_accuracy: 0.9861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2782a5fb8d0>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model on the real image\n",
    "### At first preprocessing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread('./handwrittenDigit.png')\n",
    "\n",
    "# converting the image into grayscale\n",
    "grey = cv.cvtColor(image.copy(), cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Binarize the grayscaled image (segregate the digit into white and making the rest black)\n",
    "ret, thresh = cv.threshold(grey.copy(), 75, 255, cv.THRESH_BINARY_INV)\n",
    "\n",
    "\n",
    "# Adding Further modification until it becomes a lot more similar to the image feeded in the training dataset \n",
    "_, outlines, _ = cv.findContours(thresh.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "preprocess = []\n",
    "for outline in outlines:\n",
    "    x,y,width,height = cv.boundingRect(outline)\n",
    "    \n",
    "    # Creating a rectangle around the digit in the original image \n",
    "    cv.rectangle(image, (x,y), (x+width, y+height), color=(0, 255, 0), thickness=2)\n",
    "    \n",
    "    # Refining out the digit from the image corresponding to the current outline in the for loop\n",
    "    refining_digit = thresh[y:y+height, x:x+width]\n",
    "    \n",
    "    # Resizing that digit into 18 by 18\n",
    "    resizing_digit = cv.resize(refining_digit, (18,18))\n",
    "    \n",
    "    # Padding the digit with 5 pixels of black color (zeros) in each side to finally produce the image of (28, 28)\n",
    "    padding = np.pad(resizing_digit, ((5,5),(5,5)), \"constant\", constant_values=0)\n",
    "    \n",
    "    # Adding the preprocessed digit to the list of preprocessed digits\n",
    "    preprocess.append(padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()\n",
    "prenp = np.array(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Prediction: 0\n",
      "\n",
      " Softmax Prediction from the neural network:\n",
      "\n",
      " [[6.4711809e-01 1.0435095e-03 2.1773863e-03 8.4961858e-03 1.2385094e-03\n",
      "  4.2887323e-02 9.9855274e-02 2.3574296e-04 1.9349377e-01 3.4542037e-03]]\n",
      "\n",
      "\n",
      "Pos Prediction: \n",
      "\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for refining_digit in preprocess:\n",
    "    prediction = model.predict(refining_digit.reshape(1, 28, 28, 1))   \n",
    "    print (\"\")\n",
    "    print (\"\")\n",
    "    print (\"\")\n",
    "    print (\"\")\n",
    "    plt.imshow(refining_digit.reshape(28, 28))\n",
    "    plt.show()\n",
    "    print(\"\\n\\n Prediction: {}\".format(np.argmax(prediction)))\n",
    "    print (\"\\n Softmax Prediction from the neural network:\\n\\n {}\".format(prediction))\n",
    "    shape_prediction = np.zeros(prediction.shape)\n",
    "    shape_prediction[0][np.argmax(prediction)] = 1\n",
    "    print (\"\\n\\nPos Prediction: \\n\\n {}\".format(shape_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit",
   "language": "python",
   "name": "python37264bit80703674eb31479f9bdd4d3967985fbd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
